# -*- coding: utf-8 -*-
"""AKHER_forecasting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UZIKpyK_Zf2n9G89b8Fuaj77Hbw1gXnw

Price forecasting notebook
"""
# Commented out IPython magic to ensure Python compatibility.
from datascience import *
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from scipy import stats
from scipy.stats import norm
from sklearn.datasets import make_blobs
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.compose import ColumnTransformer
import category_encoders as ce
from yellowbrick.regressor import ResidualsPlot
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
import math

from fbprophet import Prophet
from sklearn.model_selection import TimeSeriesSplit
from fbprophet import Prophet


model=''
df =''

def preparemodel2():
    global df
    global model
    """importing the data"""

    df = pd.read_csv("new_forecasting.csv", encoding='cp1252') # Read CSV into dataframe

    df

    """#Data visualization"""

    df

    df.info()

    df['USD TO EGP'].describe()

    df['unemployment'].describe()

    df['% increase'].describe()

    df['inflation'].describe()

    """#Data Cleaning

    Calculating the date
    """

    df

    df['new_year'] = df['year'].apply(str) + '-' + df['Month'].apply(str)

    df['year2'] = pd.to_datetime(df['new_year'], format='%Y-%m')

    df.drop('year', axis=1, inplace=True)

    df.drop('Month', axis=1, inplace=True)

    df.drop('month/year', axis=1, inplace=True)

    df.drop('new_year', axis=1, inplace=True)

    df['unemployment']=df['unemployment'].astype(float)

    df

    df = df.dropna()

    columns=df.columns
    k=1
    plt.figure(figsize=(25,300))
    for i in columns:
        for j in columns:
            plt.subplot(64,4,k)
            sns.scatterplot(data=df,x=i,y=j,size=5)
            k+=1

    k=1
    plt.figure(figsize=(25,20))
    for i in columns:
        plt.subplot(4,4,k)
        sns.distplot(df[i])
        k+=1

    plt.figure(figsize=(12, 8))
    sns.heatmap(df.corr(),cmap='RdBu', annot = True)
    plt.title("Correlation between Variables")
    plt.show()

    """#MODEL"""

    df

    # Simplify column names
    df.columns = ['% increase','inflation', 'USD TO EGP', 'unemployment','year2']

    targets = ['% increase']
    features = [feature for feature in df.columns if feature not in targets]
    df.head()

    downsample = df[['% increase','inflation', 'USD TO EGP', 'unemployment','year2']].resample('M', on='year2').mean().reset_index(drop=False)

    df = downsample.copy()

    df

    """TimeSeries univariante"""

    N_SPLITS = 3

    X = df['year2']
    y = df['% increase']

    folds = TimeSeriesSplit(n_splits=N_SPLITS)

    train_size = int(0.85 * len(df))
    test_size = len(df) - train_size

    univariate_df = df[['year2', '% increase']].copy()
    univariate_df.columns = ['ds', 'y']

    train = univariate_df.iloc[:train_size, :]

    x_train, y_train = pd.DataFrame(univariate_df.iloc[:train_size, 0]), pd.DataFrame(univariate_df.iloc[:train_size, 1])
    x_valid, y_valid = pd.DataFrame(univariate_df.iloc[train_size:, 0]), pd.DataFrame(univariate_df.iloc[train_size:, 1])

    print(len(train), len(x_valid))

    """Prophet model"""

    # Train the model
    model = Prophet()
    model.fit(train)

    # x_valid = model.make_future_dataframe(periods=test_size, freq='w')

    # Predict on valid set
    y_pred = model.predict(x_valid)

    # Calcuate metrics
    score_mae = mean_absolute_error(y_valid, y_pred.tail(test_size)['yhat'])
    score_rmse = math.sqrt(mean_squared_error(y_valid, y_pred.tail(test_size)['yhat']))

    print( 'RMSE: {}'.format(score_rmse))

    #print("H")

    # from statsmodels.tsa.arima_model import ARIMA

    # # Fit model
    # model = ARIMA(y_train, order=(1,1,1))
    # model_fit = model.fit()

    # # Prediction with ARIMA
    # y_pred, se, conf = model_fit.forecast(19)

    # # Calcuate metrics
    # score_mae = mean_absolute_error(y_valid, y_pred)
    # score_rmse = math.sqrt(mean_squared_error(y_valid, y_pred))

    # print( 'RMSE: {}'.format(score_rmse))

    """Auto Arima model"""

    data = univariate_df.filter(['y'])
    #Convert the dataframe to a numpy array
    dataset = data.values

    scaler = MinMaxScaler(feature_range=(-1, 0))
    scaled_data = scaler.fit_transform(dataset)

    scaled_data[:10]

    #print("H")

    look_back = 10
    # Split into train and test sets
    train, test = scaled_data[:train_size-look_back,:], scaled_data[train_size-look_back:,:]

    def create_dataset(dataset, look_back=1):
        X, Y = [], []
        for i in range(look_back, len(dataset)):
            a = dataset[i-look_back:i, 0]
            X.append(a)
            Y.append(dataset[i, 0])
        return np.array(X), np.array(Y)

    x_train, y_train = create_dataset(train, look_back)
    x_test, y_test = create_dataset(test, look_back)

    # reshape input to be [samples, time steps, features]
    x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))
    x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))

    print(len(x_train), len(x_test))

    """LSTM model"""

    df

    """TimeSeries multivariate"""

    #print("H")

    feature_columns = ['inflation', 'USD TO EGP', 'unemployment']

    target_column = ['% increase']

    train_size = int(0.85 * len(df))

    multivariate_df = df[['year2'] + target_column + feature_columns].copy()
    multivariate_df.columns = ['ds', 'y'] + feature_columns

    train = multivariate_df.iloc[:train_size, :]
    x_train, y_train = pd.DataFrame(multivariate_df.iloc[:train_size, [0,2,3,4]]), pd.DataFrame(multivariate_df.iloc[:train_size, 1])
    x_valid, y_valid = pd.DataFrame(multivariate_df.iloc[train_size:, [0,2,3,4]]), pd.DataFrame(multivariate_df.iloc[train_size:, 1])

    train.head()

    df

    train.dtypes


    # Train the model
    model = Prophet()
    model.add_regressor('inflation')
    model.add_regressor('USD TO EGP')
    model.add_regressor('unemployment')

    # Fit the model with train set
    model.fit(train)

    # Predict on valid set
    y_pred = model.predict(x_valid)

    # Calcuate metrics
    score_mae = mean_absolute_error(y_valid, y_pred['yhat'])
    score_rmse = math.sqrt(mean_squared_error(y_valid, y_pred['yhat']))

    print( 'RMSE: {}'.format(score_rmse))

    x_valid

def runmodel2(fmonth, fyear, fprice):
    global df
    global model

    """#Predicting new values"""
    
    month = fmonth # month of prediction
    year = fyear #year of prediction

    date = str(year) + "-" + str(month) + "-01"

    pd.to_datetime(date)
    #df['year2'] = pd.to_datetime(df['new_year'], format='%Y-%m')

    dates_range = pd.date_range(start =pd.to_datetime('2022-11-01'),end =date , freq ='M')

    dates_range

    inputs=[]

    for i in range(len(dates_range)):
        inputs.append([dates_range[i],0.02581,24.0714,7.40])

    print ("Inputsss ",inputs)
    #inputs
    #Xnew = pd.DataFrame(pd.np.empty((0, 4))) 
    
    Xnew = pd.DataFrame(inputs) 

    Xnew.columns = ['ds','inflation','USD TO EGP','unemployment']

    Xnew

    new  = model.predict(Xnew)

    new

    new['yhat']

    x = new['yhat'].sum()

    x =-x

    x

    price = fprice #price of prediction

    price = price + price * x/ 100

    print(price)
    
    return price


if __name__ == '__main__':
    preparemodel2()
    runmodel2(11, 2026, 10000000)

